{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is designed to read in the raw .cvs files produced by the laser triangulation sensor used to measure displancemt of the pendulum thrust stand deployed in the university of Southampon's main vacuum chamber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Aug 23 12:36:10 2020\n",
    "@author: Thomas Munro-O'Brien\n",
    "\"\"\"\n",
    "#import useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.misc import derivative as deriv\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopefully, the only input needed from you for this code to work, is to the \"Path\" name, and \"save_as\", then run through the rest of the code and the output will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Path' should be the directory path used to store the test data and/or the previous years data. The 'save_as' will be the name of the output .csv file which will be saved in the same location as the python code.\n",
    "\n",
    "*It is important to use forwardslashes instead as backslashes as a backslash is a speciel charactor for python. Alternatively two backslashes can be used.*\n",
    "\n",
    "The asterix is known as a wild card charactor in python so all files in the format of 'anything'.csv will be selected. If the files are spread over multiple folders \"/ * / * .csv\" can be used. \n",
    "\n",
    "If a file with the same name as the save_as already exists, it will be overwritten.\n",
    "\n",
    "If you trying to run this on mac the syntax of file paths might be different and could lead to some issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'C:/Users/tfmo1\\\\OneDrive - University of Southampton/Documents/Work Soton/Calibartion data 16-06-2021/*/*.csv'\n",
    "save_as = 'Calibration data 16-06-2021'\n",
    "#For lab 7 and 8 the data is placed into sub folders, this can be pathed with an additional /* before the .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_list = [] #List used to store file names for later use\n",
    "y_diff_list = [] #List used to store output before being written to .csv file\n",
    "test_name = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to define the function that will read the data within the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_dif(file_name_to_test):\n",
    "    df = pd.read_csv(file_name_to_test,skiprows=[0,1,2,3,4], delimiter=\",\", header=None, usecols=[0,1], names=['Time Stamp', 'Distance [mm]'])\n",
    "    \n",
    "    \"\"\"Depending on if the data is new or from past years, that used a different laser, the files are formatted differently.\n",
    "    The try options attempts to read it as the new laser but if fails, uses the old laser format. 'fc' is a value that \n",
    "    you might want to change if the code is not filtering the data well. \"\"\"\n",
    "    \n",
    "    X = df['Time Stamp']\n",
    "    Y = df['Distance [mm]']\n",
    "    \n",
    "    fs = 5000 # Sampling frequency\n",
    "    #If data reduction was used the sampling frequency will need to be changed\n",
    "    fc = 0.750 # Cut-off frequency of the filter\n",
    "\n",
    "        \n",
    "    t = np.arange(0,Y.size,1)# Generate the time vector \n",
    "    w = fc / (fs / 2) # Normalize the frequency\n",
    "    \n",
    "    b, a = signal.butter(4, w, 'low') #Applies a Butterworths low pass filter\n",
    "    \n",
    "    output = signal.filtfilt(b, a, Y)\n",
    "    \n",
    "    output_dif = np.diff(output) #Differentiates the filtered signal\n",
    "    \n",
    "    Title = file_name_to_test.split('/')[-1] #Makes a title\n",
    "    \n",
    "    xy = np.array([t,output])\n",
    "    xy_dif = np.array([t[:-1],output_dif])\n",
    "\n",
    "    \"\"\"Due to the way the Butterworth signal filter works it is benifical to skip the begining\n",
    "    and ends of the data whilst analysing.\"\"\"\n",
    "    \n",
    "    skip_left = int(round((0.1*output_dif.size),0)) #Skips the first 10% of the output\n",
    "    \n",
    "    skip_right = output_dif.size - int(round((0.1*output_dif.size),0)) #Skips the last 10% of the output\n",
    "    \n",
    "    max_index = np.argmax(output_dif[skip_left:skip_right]) + skip_left #Finds the index of the point of max rate of change\n",
    "    a,b = xy[:,:max_index],xy[:,max_index:] #Splits the output about the point of max rate of change\n",
    "    \n",
    "    \"\"\"It is also good to remove the transitional period from the data before averaging, as such, the last 10% of the\n",
    "    left, and first 10% of the right is skipped.\"\"\"\n",
    "    \n",
    "    a_skip = int(len(a[1,:]) * 0.25) #Skips the last 10% of the left partition\n",
    "    b_skip = int(len(b[1,:]) * 0.25) #Skips the first 10% of the right partition\n",
    "\n",
    "    a_range = np.arange(a_skip,int((len(a[1,:])-a_skip))-1,1)\n",
    "    b_range = np.arange(b_skip,int((len(b[1,:])-b_skip))-1,1)\n",
    "\n",
    "    a_sum = 0\n",
    "    b_sum = 0\n",
    "\n",
    "    for i in a_range:\n",
    "        a_sum += a[1,i]\n",
    "\n",
    "    for i in b_range:\n",
    "        b_sum += b[1,i]\n",
    "\n",
    "    mean_a = a_sum/len(a_range) #The mean y_dis of the left partition\n",
    "    mean_b = b_sum/len(b_range) #The mean y_dis of the right partition\n",
    "\n",
    "    Y_dif = mean_b - mean_a \n",
    "\n",
    "    save_fig = True #Can be changed if you do not want to save the figures\n",
    "\n",
    "    plt.title(Title + \" :\" + str(round(Y_dif,5)) + \"mm\")\n",
    "    plt.plot(t,output)\n",
    "    plt.plot([a[0,a_skip],a[0,(len(a[1,:])-a_skip)]],[mean_a,mean_a])\n",
    "    plt.plot([b[0,b_skip],b[0,(len(b[1,:])-b_skip)]],[mean_b,mean_b])\n",
    "    if save_fig == True:\n",
    "        plt.savefig(\"{}.png\".format(file_name_to_test))\n",
    "    plt.show()\n",
    "    return(abs(Y_dif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to direct python to go to where the files are saved and to iterate over each .csv file its finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in glob.iglob(Path):\n",
    "    file_name_list.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Calibartion data 16-06-2021\\\\Pyramid run\\\\protocol_optoNCDT ILD1750_2021-06-16_15-48-37.250.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-dfc093da46dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_name_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Y_dif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlist_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlist_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mlist_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-2e51398b9087>\u001b[0m in \u001b[0;36mget_Y_dif\u001b[1;34m(file_name_to_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_Y_dif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_to_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_to_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time Stamp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Distance [mm]'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"Depending on if the data is new or from past years, that used a different laser, the files are formatted differently.\n\u001b[0;32m      5\u001b[0m     \u001b[0mThe\u001b[0m \u001b[1;32mtry\u001b[0m \u001b[0moptions\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mlaser\u001b[0m \u001b[0mbut\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muses\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mold\u001b[0m \u001b[0mlaser\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;34m'fc'\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mthat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Calibartion data 16-06-2021\\\\Pyramid run\\\\protocol_optoNCDT ILD1750_2021-06-16_15-48-37.250.csv'"
     ]
    }
   ],
   "source": [
    "for i in file_name_list:\n",
    "    y_diff = get_Y_dif(i)\n",
    "    list_name = i.split('\\\\')\n",
    "    name =  list_name[-1] +\" \"+ list_name[-2]\n",
    "    test_name.append(name)\n",
    "    print(name,y_diff)\n",
    "    y_diff_list.append(y_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the output data the file names and y_diff values are compiled into a dictionary and then into a panda dataframe. Once in the form of a dataframe, it can be easily save as a .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"Y_dif (mm)\":y_diff_list,\"File_name\":test_name}\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(\"{}.csv\".format(save_as),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a file that contains the y_diff values in one column and the file name in the next.\n",
    "\n",
    "If the dataframe is empty, the most likely issue is that path is incorrect.\n",
    "\n",
    "If the raw data was saved under file name in the formate \"00 m_a 00 m_c 00 voltage 00 current .csv\" it can be easily decoded. By opening the outputed .csv in MS Excel and then using the \"Text to Columns\" function found on the data tab, the file name column can be turned into individual columns by selecting the correct deliminator, in the case suggested above the deliminator is space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
